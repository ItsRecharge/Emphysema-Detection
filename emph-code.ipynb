{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9187894,"sourceType":"datasetVersion","datasetId":5554065},{"sourceId":9235599,"sourceType":"datasetVersion","datasetId":5586300}],"dockerImageVersionId":30746,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false},"colab":{"provenance":[],"gpuType":"T4","name":"Emph code"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"73f0f3e5a3364004811e14f88d04b53a":{"model_module":"@jupyter-widgets/controls","model_name":"VBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":["IPY_MODEL_cd9c09185cd54949bf9b6f00626fa759","IPY_MODEL_49648014e40b49dc9552896832f206cc","IPY_MODEL_2ad36c47b39c4d01b1213a521d76ca50","IPY_MODEL_0e4254270d1340209093a8c510efe0a5","IPY_MODEL_ab4ba10c74ee49f7943f77c674b3df9f"],"layout":"IPY_MODEL_0b073698d3ea4ec3851b6676057311a8"}},"cd9c09185cd54949bf9b6f00626fa759":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f081bf96f6b34a0ca7e4f3441f3924d6","placeholder":"​","style":"IPY_MODEL_c4560ccae0f143a1bb8a766d5c2e5e9d","value":"<center> <img\nsrc=https://www.kaggle.com/static/images/site-logo.png\nalt='Kaggle'> <br> Create an API token from <a\nhref=\"https://www.kaggle.com/settings/account\" target=\"_blank\">your Kaggle\nsettings page</a> and paste it below along with your Kaggle username. <br> </center>"}},"49648014e40b49dc9552896832f206cc":{"model_module":"@jupyter-widgets/controls","model_name":"TextModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"TextModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"TextView","continuous_update":true,"description":"Username:","description_tooltip":null,"disabled":false,"layout":"IPY_MODEL_0133669f738341d38a177d53732e3ab2","placeholder":"​","style":"IPY_MODEL_eb85dfb1e3fd4330a28e54382389bd05","value":""}},"2ad36c47b39c4d01b1213a521d76ca50":{"model_module":"@jupyter-widgets/controls","model_name":"PasswordModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"PasswordModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"PasswordView","continuous_update":true,"description":"Token:","description_tooltip":null,"disabled":false,"layout":"IPY_MODEL_8b8be017df5141f19c2c94e057bfd398","placeholder":"​","style":"IPY_MODEL_f27d1717141d49d6a21184eef77d3be9","value":""}},"0e4254270d1340209093a8c510efe0a5":{"model_module":"@jupyter-widgets/controls","model_name":"ButtonModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ButtonModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ButtonView","button_style":"","description":"Login","disabled":false,"icon":"","layout":"IPY_MODEL_98fec22c2b594eaaa69a61ad2bd284f6","style":"IPY_MODEL_2c410fcfc4fc414887b27a196263e1f4","tooltip":""}},"ab4ba10c74ee49f7943f77c674b3df9f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c51288d313cf410fbf939ebd14889ce8","placeholder":"​","style":"IPY_MODEL_1d22da052f9f4baa8bd509f180a171c0","value":"\n<b>Thank You</b></center>"}},"0b073698d3ea4ec3851b6676057311a8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":"center","align_self":null,"border":null,"bottom":null,"display":"flex","flex":null,"flex_flow":"column","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"50%"}},"f081bf96f6b34a0ca7e4f3441f3924d6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c4560ccae0f143a1bb8a766d5c2e5e9d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0133669f738341d38a177d53732e3ab2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eb85dfb1e3fd4330a28e54382389bd05":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8b8be017df5141f19c2c94e057bfd398":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f27d1717141d49d6a21184eef77d3be9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"98fec22c2b594eaaa69a61ad2bd284f6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2c410fcfc4fc414887b27a196263e1f4":{"model_module":"@jupyter-widgets/controls","model_name":"ButtonStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ButtonStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","button_color":null,"font_weight":""}},"c51288d313cf410fbf939ebd14889ce8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1d22da052f9f4baa8bd509f180a171c0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**https://github.com/aladdinpersson/Machine-Learning-Collection/tree/master/ML/Pytorch/Basics/custom_dataset**","metadata":{"id":"1mTzQ8NpUFTf"}},{"cell_type":"code","source":"import os\nfrom pathlib import Path\n\ndata_entry_path = Path(neelmbansal_emphysema_dataset_from_nih_chest_x_ray_path) / \"Data_Entry_2024.csv\"\ndataset_path = Path(neelmbansal_emphysema_dataset_from_nih_chest_x_ray_path) / \"emphReform/emphReform\"\n","metadata":{"id":"3BRh8Dt-Gs2v"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install grad-cam\nimport os\nimport pandas as pd\nimport torch\nfrom torch.utils.data import Dataset\nfrom skimage import io\nfrom PIL import Image\nimport matplotlib.pyplot as plt\n\nclass Emphysema_Dataset(Dataset):\n    def __init__(self, csv_file, root_dir, transform=None):\n        self.annotations = pd.read_csv(csv_file)\n        self.root_dir = root_dir\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.annotations)\n\n    def __getitem__(self, index):\n        img_path = os.path.join(self.root_dir, self.annotations.iloc[index, 0])\n        image = io.imread(img_path)\n        image = Image.fromarray(image).convert('RGB')  # Convert the NumPy array to a PIL Image\n        y_label = torch.tensor(self.annotations.iloc[index, 1])\n\n        if self.transform:\n            image = self.transform(image)\n\n        return image, y_label\n\n%load_ext tensorboard","metadata":{"id":"ZNOatwc51Psn","outputId":"d35f60f9-8efb-4545-d94a-1d2578ce9fb6","execution":{"iopub.status.busy":"2024-12-27T18:05:52.049094Z","iopub.execute_input":"2024-12-27T18:05:52.049364Z","iopub.status.idle":"2024-12-27T18:09:49.084751Z","shell.execute_reply.started":"2024-12-27T18:05:52.049325Z","shell.execute_reply":"2024-12-27T18:09:49.083525Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from google.colab import output\n\n# JavaScript code to prevent timeout\ncode = \"\"\"\nfunction KeepClicking(){\n    console.log(\"Clicking to prevent timeout\");\n    document.querySelector(\"colab-toolbar-button\").click();\n}\nsetInterval(KeepClicking, 60000);\n\"\"\"\n\noutput.eval_js(code)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-27T18:09:49.087018Z","iopub.execute_input":"2024-12-27T18:09:49.087528Z","iopub.status.idle":"2024-12-27T18:09:49.2885Z","shell.execute_reply.started":"2024-12-27T18:09:49.087484Z","shell.execute_reply":"2024-12-27T18:09:49.286045Z"},"id":"RA-osku6_CUg","outputId":"adab25ed-5102-41bd-a52b-456c3037960a"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#%tensorboard --logdir logs/resnet\n\n# Import necessary libraries\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision\nimport torchvision.transforms as transforms\nfrom torchvision import models\nfrom pathlib import Path\nfrom PIL import Image\n#import tmm\n\nfrom torch.utils.tensorboard import SummaryWriter\nwriter = SummaryWriter(log_dir='./logs/resnet')\n\n# Set device (use GPU if available)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(device,\"||\",torch.device)\n\n# Load Emphysema_Dataset  (host domain)\ntransform = transforms.Compose([\n  transforms.Resize((224, 224)),  # Resize images to the size expected by ResNet50 originally 1024 x1024\n  transforms.ToTensor(),\n  transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),  # Normalize based on ImageNet stats\n])\n\n\ndataset = Emphysema_Dataset(csv_file = data_entry_path, root_dir= dataset_path, transform=transform)\n\ntrain_size = int(0.3 * len(dataset)) ## 0.6 is 60% split for train and testclea\ntest_size = len(dataset) - train_size\ntrain_set, test_set = torch.utils.data.random_split(dataset, [train_size, test_size])\n\ntrain_loader = torch.utils.data.DataLoader(train_set, batch_size=96, shuffle=True)\ntest_loader = torch.utils.data.DataLoader(test_set, batch_size=96, shuffle=False)","metadata":{"id":"4Hthdgbr1Pso","outputId":"be27af3f-c4c7-46a5-b299-1023a9ac964d","execution":{"iopub.status.busy":"2024-12-27T18:09:49.289301Z","iopub.status.idle":"2024-12-27T18:09:49.289725Z","shell.execute_reply.started":"2024-12-27T18:09:49.289511Z","shell.execute_reply":"2024-12-27T18:09:49.289531Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from pytorch_grad_cam import GradCAM, HiResCAM, ScoreCAM, GradCAMPlusPlus, AblationCAM, XGradCAM, EigenCAM, FullGrad\nfrom pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\nfrom pytorch_grad_cam.utils.image import show_cam_on_image, deprocess_image, preprocess_image\nimport cv2\nimport numpy as np\n\ndef gradcam_PPI (img_pth, device):\n\n    # Check if the image file exists\n    if not Path(img_pth).is_file():\n        raise FileNotFoundError(f\"Image file not found: {img_pth}\")\n\n    rgb_img = cv2.imread(img_pth)[:, :, ::-1]\n    rgb_img = np.float32(rgb_img) / 255\n    input_tensor = preprocess_image(rgb_img, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]).to(device)\n\n    return rgb_img, input_tensor\n\npic1_rgb_img, pic1_input_tensor = gradcam_PPI(str(Path(dataset_path / \"00000002_000.png\")), device)\npic2_rgb_img, pic2_input_tensor = gradcam_PPI(str(Path(dataset_path / \"00000009_000.png\")), device)\n","metadata":{"id":"WfHeBAz72jCq","execution":{"iopub.status.busy":"2024-12-27T18:09:49.29135Z","iopub.status.idle":"2024-12-27T18:09:49.291745Z","shell.execute_reply.started":"2024-12-27T18:09:49.291575Z","shell.execute_reply":"2024-12-27T18:09:49.291591Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import f1_score, precision_score, roc_auc_score\n\n# Training function\ndef train_model(model, train_loader, criterion, optimizer, num_epochs):\n    model.train()\n    print(\"i am here with\", num_epochs)\n    for epoch in range(num_epochs):\n        print(f'Epoch {epoch + 1}/{num_epochs}')\n        print('-' * 10)\n        running_loss = 0.0\n        for inputs, labels in train_loader:\n            inputs, labels = inputs.to(device), labels.to(device)\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            running_loss += loss.item()\n\n        model.eval()\n\n            # Log the training loss\n        epoch_loss = running_loss / len(train_loader)\n        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {running_loss / len(train_loader):.4f}')\n\n        writer.add_scalar('Training Loss', epoch_loss, epoch + 1)\n\n\n        correct = 0 ##to calc accuracy\n        total = 0\n        extended_predicted = []\n        extended_probabilities = []\n        extended_labels = []\n        with torch.no_grad():\n            for inputs, labels in test_loader:\n                inputs, labels = inputs.to(device), labels.to(device)\n                outputs = model(inputs)\n                _, predicted = torch.max(outputs.data, 1)\n                total += labels.size(0)\n                correct += (predicted == labels).sum().item()\n                probabilities = torch.softmax(outputs, dim=1)[:, 1].cpu().numpy()\n                extended_probabilities.extend(probabilities)\n                extended_predicted.extend(predicted.cpu().numpy())\n                extended_labels.extend(labels.cpu().numpy())\n\n        accuracy = 100 * correct / total\n        print(f'Accuracy of the model on the test images: {accuracy:.2f}%')\n\n        f1 = f1_score(extended_labels, extended_predicted)\n        precision = precision_score(extended_labels, extended_predicted)\n        auc = roc_auc_score(extended_labels, extended_probabilities)\n\n        writer.add_scalar('F1 Score', f1, epoch + 1)\n        writer.add_scalar('Precision', precision, epoch + 1)\n        writer.add_scalar('AUC', auc, epoch + 1)\n\n##-- For Gradcan\n\n        target_layers = [model.layer4[-1]]\n        # Note: input_tensor can be a batch tensor with several images!\n\n        # We have to specify the target we want to generate the CAM for.\n        targets = [ClassifierOutputTarget(1)]\n\n\n        # Construct the CAM object once, and then re-use it on many images.\n        with GradCAM(model=model, target_layers=target_layers) as cam:\n          # You can also pass aug_smooth=True and eigen_smooth=True, to apply smoothing.\n          gc1 = cam(input_tensor=pic1_input_tensor, targets=targets)[0, :]\n          # In this example gc1 has only one image in the batch:\n          visualization1 = show_cam_on_image(pic1_rgb_img, gc1, use_rgb=True)\n          # You can also get the model outputs without having to redo inference\n          # You can also pass aug_smooth=True and eigen_smooth=True, to apply smoothing.\n          gc2 = cam(input_tensor=pic2_input_tensor, targets=targets)[0, :]\n          # In this example gc2 has only one image in the batch:\n          visualization2 = show_cam_on_image(pic2_rgb_img, gc2, use_rgb=True)\n          # You can also get the model outputs without having to redo inference\n\n          writer.add_image(f\"Grad-CAM/Image1/Epoch_{(epoch+1)}\", visualization1, epoch+1, dataformats=\"HWC\")\n          writer.add_image(f\"Grad-CAM/Image2/Epoch_{(epoch+1)}\", visualization2, epoch+1, dataformats=\"HWC\")\n\n\n          #model_outputs = cam.outputs\n\n          #import matplotlib.pyplot as plt\n          #plt.imshow(visualization)\n          #plt.axis('off')\n          #plt.show()\n\n        # Log the test accuracy\n        writer.add_scalar('Test Accuracy', accuracy, epoch + 1)\n\n\n\n        model.train()","metadata":{"id":"L4LxYPb8bWE-","execution":{"iopub.status.busy":"2024-12-27T18:09:49.294407Z","iopub.status.idle":"2024-12-27T18:09:49.294824Z","shell.execute_reply.started":"2024-12-27T18:09:49.294652Z","shell.execute_reply":"2024-12-27T18:09:49.294669Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def modelResnet():\n\n    model = models.resnet50(pretrained=True)\n\n\n\n    model.fc = nn.Linear(model.fc.in_features, 2)  # Emphysema_Dataset has 2 classes\n    model = model.to(device)\n\n    # Define loss function and optimizer\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.Adam(model.parameters(), lr=0.001)\n\n\n    return model, criterion, optimizer","metadata":{"id":"c1HpDg61Y0-J","execution":{"iopub.status.busy":"2024-12-27T18:09:49.295621Z","iopub.status.idle":"2024-12-27T18:09:49.295936Z","shell.execute_reply.started":"2024-12-27T18:09:49.29578Z","shell.execute_reply":"2024-12-27T18:09:49.295794Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"","metadata":{"id":"AN4iHJKw_CUi"}},{"cell_type":"code","source":"# Train and evaluate the model\n#model = Image.fromarray(model)\n\nmodel, criterion, optimizer = modelResnet()\n\n\nepochs = input(\"How Many Epochs?: \")\n\n##. ASK FUTURE TYPES OF MODEL TO RUN AND BATCH SIZE\n\n","metadata":{"id":"QzlPcKe5UFTh","outputId":"37d8696d-6634-4ea1-9fa7-36fb4bb4611c","execution":{"iopub.status.busy":"2024-12-27T18:09:49.297111Z","iopub.status.idle":"2024-12-27T18:09:49.29742Z","shell.execute_reply.started":"2024-12-27T18:09:49.297276Z","shell.execute_reply":"2024-12-27T18:09:49.297289Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_model(model, train_loader, criterion, optimizer, num_epochs=int(epochs))","metadata":{"id":"9v3FXGpdbBHL","outputId":"3c753f6e-c6f3-4f43-fd95-cd5b1b7e162b","execution":{"iopub.status.busy":"2024-12-27T18:09:49.298953Z","iopub.status.idle":"2024-12-27T18:09:49.299267Z","shell.execute_reply.started":"2024-12-27T18:09:49.299119Z","shell.execute_reply":"2024-12-27T18:09:49.299133Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"","metadata":{"id":"N7GAg2y59InN"}},{"cell_type":"markdown","source":"https://github.com/jacobgil/pytorch-grad-cam","metadata":{"id":"CBgsGp3bbOW8"}},{"cell_type":"code","source":"writer.close()\n# Save the trained model","metadata":{"id":"RBgUx8zpUPEk","execution":{"iopub.status.busy":"2024-12-27T18:09:49.300707Z","iopub.status.idle":"2024-12-27T18:09:49.301059Z","shell.execute_reply.started":"2024-12-27T18:09:49.300893Z","shell.execute_reply":"2024-12-27T18:09:49.300908Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"torch.save(model.state_dict(), 'trained_model.pth')\n","metadata":{"id":"qV-By5ywUPKZ","execution":{"iopub.status.busy":"2024-12-27T18:09:49.302075Z","iopub.status.idle":"2024-12-27T18:09:49.302364Z","shell.execute_reply.started":"2024-12-27T18:09:49.302222Z","shell.execute_reply":"2024-12-27T18:09:49.302235Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%tensorboard --logdir logs/resnet","metadata":{"id":"AKojXSenUFTh","execution":{"iopub.status.busy":"2024-12-27T18:09:49.303964Z","iopub.status.idle":"2024-12-27T18:09:49.304298Z","shell.execute_reply.started":"2024-12-27T18:09:49.304133Z","shell.execute_reply":"2024-12-27T18:09:49.304155Z"},"trusted":true,"outputId":"7de33e5a-9f3b-45a4-c77a-450639adfe95"},"outputs":[],"execution_count":null}]}