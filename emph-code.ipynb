{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9187894,"sourceType":"datasetVersion","datasetId":5554065},{"sourceId":9235599,"sourceType":"datasetVersion","datasetId":5586300}],"dockerImageVersionId":30746,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false},"colab":{"provenance":[],"machine_shape":"hm","gpuType":"T4","name":"Emph code"},"accelerator":"GPU"},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**https://github.com/aladdinpersson/Machine-Learning-Collection/tree/master/ML/Pytorch/Basics/custom_dataset**","metadata":{"id":"1mTzQ8NpUFTf"}},{"cell_type":"code","source":"!pip install tensorflow tensorboard tf-keras-vis grad-cam\nimport os\nimport pandas as pd\nimport torch\nfrom torch.utils.data import Dataset\nfrom skimage import io\nfrom PIL import Image\nimport matplotlib.pyplot as plt\n\nclass Emphysema_Dataset(Dataset):\n    def __init__(self, csv_file, root_dir, transform=None):\n        self.annotations = pd.read_csv(csv_file)\n        self.root_dir = root_dir\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.annotations)\n\n    def __getitem__(self, index):\n        img_path = os.path.join(self.root_dir, self.annotations.iloc[index, 0])\n        image = io.imread(img_path)\n        image = Image.fromarray(image).convert('RGB')  # Convert the NumPy array to a PIL Image\n        y_label = torch.tensor(self.annotations.iloc[index, 1])\n\n        if self.transform:\n            image = self.transform(image)\n\n        return image, y_label\n\n%load_ext tensorboard","metadata":{"execution":{"iopub.status.busy":"2024-08-16T20:39:11.584549Z","iopub.execute_input":"2024-08-16T20:39:11.585875Z","iopub.status.idle":"2024-08-16T20:39:11.596865Z","shell.execute_reply.started":"2024-08-16T20:39:11.58582Z","shell.execute_reply":"2024-08-16T20:39:11.595438Z"},"id":"ZNOatwc51Psn","colab":{"base_uri":"https://localhost:8080/"},"outputId":"589a264e-0e05-460e-ad38-20629b7b278e","trusted":true},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":"Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.0)\n\nRequirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (2.17.0)\n\nCollecting tf-keras-vis\n\n  Downloading tf_keras_vis-0.8.7-py3-none-any.whl.metadata (10 kB)\n\nCollecting grad-cam\n\n  Downloading grad-cam-1.5.3.tar.gz (7.8 MB)\n\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m68.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\n\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n\n  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n\n  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n\nRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n\nRequirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n\nRequirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n\nRequirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n\nRequirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n\nRequirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.11.0)\n\nRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n\nRequirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.0)\n\nRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.1)\n\nRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n\nRequirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n\nRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (71.0.4)\n\nRequirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n\nRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n\nRequirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n\nRequirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n\nRequirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.1)\n\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n\nRequirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.26.4)\n\nRequirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.7)\n\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (0.7.2)\n\nRequirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.0.4)\n\nRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from tf-keras-vis) (1.13.1)\n\nRequirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from tf-keras-vis) (9.4.0)\n\nCollecting deprecated (from tf-keras-vis)\n\n  Downloading Deprecated-1.2.14-py2.py3-none-any.whl.metadata (5.4 kB)\n\nRequirement already satisfied: imageio in /usr/local/lib/python3.10/dist-packages (from tf-keras-vis) (2.34.2)\n\nRequirement already satisfied: torch>=1.7.1 in /usr/local/lib/python3.10/dist-packages (from grad-cam) (2.4.0+cu121)\n\nRequirement already satisfied: torchvision>=0.8.2 in /usr/local/lib/python3.10/dist-packages (from grad-cam) (0.19.0+cu121)\n\nCollecting ttach (from grad-cam)\n\n  Downloading ttach-0.0.3-py3-none-any.whl.metadata (5.2 kB)\n\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from grad-cam) (4.66.5)\n\nRequirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from grad-cam) (4.10.0.84)\n\nRequirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from grad-cam) (3.7.1)\n\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from grad-cam) (1.3.2)\n\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n\nRequirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (13.8.0)\n\nRequirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n\nRequirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.12.1)\n\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.8)\n\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.0.7)\n\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.7.4)\n\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->grad-cam) (3.15.4)\n\nRequirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->grad-cam) (1.13.2)\n\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->grad-cam) (3.3)\n\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->grad-cam) (3.1.4)\n\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->grad-cam) (2024.6.1)\n\nRequirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard) (2.1.5)\n\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->grad-cam) (1.3.0)\n\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->grad-cam) (0.12.1)\n\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->grad-cam) (4.53.1)\n\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->grad-cam) (1.4.5)\n\nRequirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->grad-cam) (3.1.4)\n\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->grad-cam) (2.8.2)\n\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->grad-cam) (1.4.2)\n\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->grad-cam) (3.5.0)\n\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.16.1)\n\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.7.1->grad-cam) (1.3.0)\n\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n\nDownloading tf_keras_vis-0.8.7-py3-none-any.whl (52 kB)\n\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.5/52.5 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\n\u001b[?25hDownloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n\nDownloading ttach-0.0.3-py3-none-any.whl (9.8 kB)\n\nBuilding wheels for collected packages: grad-cam\n\n  Building wheel for grad-cam (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n\n  Created wheel for grad-cam: filename=grad_cam-1.5.3-py3-none-any.whl size=38656 sha256=3fe71f5ac4761631d84a3c234301095dd3f972e80a44f03b53878056f47891a3\n\n  Stored in directory: /root/.cache/pip/wheels/2e/ce/70/fe64f851895eae830b3c63ec7fc464cfa7c81aeb7ad4f68063\n\nSuccessfully built grad-cam\n\nInstalling collected packages: ttach, deprecated, tf-keras-vis, grad-cam\n\nSuccessfully installed deprecated-1.2.14 grad-cam-1.5.3 tf-keras-vis-0.8.7 ttach-0.0.3\n"}]},{"cell_type":"code","source":"#%tensorboard --logdir logs/resnet\n\n# Import necessary libraries\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision\nimport torchvision.transforms as transforms\nfrom torchvision import models\nfrom pathlib import Path\nfrom PIL import Image\n#import tmm\n\nfrom torch.utils.tensorboard import SummaryWriter\nwriter = SummaryWriter(log_dir='./logs/resnet')\n\n# Set device (use GPU if available)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(device,\"||\",torch.device)\n\n# Load Emphysema_Dataset  (host domain)\ntransform = transforms.Compose([\n  transforms.Resize((224, 224)),  # Resize images to the size expected by ResNet50 originally 1024 x1024\n  transforms.ToTensor(),\n  transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),  # Normalize based on ImageNet stats\n])\n\n\ndataset = Emphysema_Dataset(csv_file = Path(\"/kaggle/input/emphysema-dataset-from-nih-chest-x-ray/Data_Entry_2024.csv\"), root_dir= Path(\"/kaggle/input/emphysema-dataset-from-nih-chest-x-ray/emphReform/emphReform\"), transform=transform)\n\ntrain_size = int(0.3 * len(dataset)) ## 0.6 is 60% split for train and testclea\ntest_size = len(dataset) - train_size\ntrain_set, test_set = torch.utils.data.random_split(dataset, [train_size, test_size])\n\ntrain_loader = torch.utils.data.DataLoader(train_set, batch_size=32, shuffle=True)\ntest_loader = torch.utils.data.DataLoader(test_set, batch_size=32, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2024-08-16T20:39:11.59892Z","iopub.execute_input":"2024-08-16T20:39:11.599278Z","iopub.status.idle":"2024-08-16T20:39:32.572712Z","shell.execute_reply.started":"2024-08-16T20:39:11.599249Z","shell.execute_reply":"2024-08-16T20:39:32.570743Z"},"id":"4Hthdgbr1Pso","outputId":"fd05de1f-86f1-4daa-f2e1-56b7a34a8347","colab":{"base_uri":"https://localhost:8080/"},"trusted":true},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":"cuda || <class 'torch.device'>\n"}]},{"cell_type":"code","source":"def modelResnet():\n\n    model = models.resnet50(pretrained=True)\n\n\n    #model = timm.create_model('xception', pretrained=True)\n    #model.eval()\n\n    model.fc = nn.Linear(model.fc.in_features, 2)  # Emphysema_Dataset has 2 classes\n    model = model.to(device)\n\n    # Define loss function and optimizer\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.Adam(model.parameters(), lr=0.001)\n\n\n    return model, criterion, optimizer","metadata":{"id":"c1HpDg61Y0-J"},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"from torchvision.models import vit_b_16\n\ndef modelViT():\n\n    model = vit_b_16(pretrained=True)\n\n    #model.fc = nn.Linear(model.fc.in_features, 2)  # Emphysema_Dataset has 2 classes\n    model.heads.head = nn.Linear(model.heads.head.in_features, 2)\n    model = model.to(device)\n\n    # Define loss function and optimizer\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.Adam(model.parameters(), lr=0.001)\n\n    print(model)\n\n\n    return model, criterion, optimizer","metadata":{"id":"s_Zz4qaVY4Tq"},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"\n# Training function\ndef train_model(model, train_loader, criterion, optimizer, num_epochs):\n    model.train()\n    print(\"i am here with\", num_epochs)\n    for epoch in range(num_epochs):\n        print(f'Epoch {epoch + 1}/{num_epochs}')\n        print('-' * 10)\n        running_loss = 0.0\n        for inputs, labels in train_loader:\n            inputs, labels = inputs.to(device), labels.to(device)\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            running_loss += loss.item()\n\n            # Log the training loss\n        epoch_loss = running_loss / len(train_loader)\n        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {running_loss / len(train_loader):.4f}')\n\n        writer.add_scalar('Training Loss', epoch_loss, epoch + 1)\n\n\n    model.eval()\n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for inputs, labels in test_loader:\n            inputs, labels = inputs.to(device), labels.to(device)\n            outputs = model(inputs)\n            _, predicted = torch.max(outputs.data, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n\n    accuracy = 100 * correct / total\n    print(f'Accuracy of the model on the test images: {accuracy:.2f}%')\n\n\n    # Log the test accuracy\n    writer.add_scalar('Test Accuracy', accuracy, epoch + 1)","metadata":{"id":"L4LxYPb8bWE-"},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# Train and evaluate the model\n#model = Image.fromarray(model)\n\nWhichModel = input(\"what model, resnet or vit? \")\nif WhichModel == \"resnet\":\n    model, criterion, optimizer = modelResnet()\nelif WhichModel == \"vit\":\n    model, criterion, optimizer = modelViT()\nelse:\n    raise Exception(\"Sorry, Chose from list\")\n\nepochs = input(\"How Many Epochs?: \")\n\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QzlPcKe5UFTh","outputId":"0ecbdf85-e0dd-4465-e154-8ea8db7319ac"},"execution_count":8,"outputs":[{"name":"stdout","output_type":"stream","text":"what model, resnet or vit? resnet\n"},{"output_type":"stream","name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n\n  warnings.warn(\n\n/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n\n  warnings.warn(msg)\n\nDownloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n\n100%|██████████| 97.8M/97.8M [00:00<00:00, 152MB/s]\n"},{"name":"stdout","output_type":"stream","text":"How Many Epochs?: 1\n"}]},{"cell_type":"code","source":"train_model(model, train_loader, criterion, optimizer, num_epochs=int(epochs))","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9v3FXGpdbBHL","outputId":"89ca330d-7ba0-4e96-85e7-bd4fdc30592e"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":"i am here with 1\n\nEpoch 1/1\n\n----------\n\nEpoch [1/1], Loss: 0.7109\n\nAccuracy of the model on the test images: 57.68%\n"}]},{"cell_type":"markdown","source":"","metadata":{"id":"N7GAg2y59InN"}},{"cell_type":"markdown","source":"https://github.com/jacobgil/pytorch-grad-cam","metadata":{"id":"CBgsGp3bbOW8"}},{"cell_type":"code","source":"from pytorch_grad_cam import GradCAM, HiResCAM, ScoreCAM, GradCAMPlusPlus, AblationCAM, XGradCAM, EigenCAM, FullGrad\nfrom pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\nfrom pytorch_grad_cam.utils.image import show_cam_on_image, deprocess_image, preprocess_image\nimport cv2\nimport numpy as np\n\n\nrgb_img = cv2.imread(\"/kaggle/input/emphysema-dataset-from-nih-chest-x-ray/emphReform/emphReform/00000002_000.png\", 1)[:, :, ::-1]\nrgb_img = np.float32(rgb_img) / 255\ninput_tensor = preprocess_image(rgb_img, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]).to(device)\n\ntarget_layers = [model.layer4[-1]]\n# Note: input_tensor can be a batch tensor with several images!\n\n# We have to specify the target we want to generate the CAM for.\ntargets = [ClassifierOutputTarget(1)]\n\n# Construct the CAM object once, and then re-use it on many images.\nwith GradCAM(model=model, target_layers=target_layers) as cam:\n  # You can also pass aug_smooth=True and eigen_smooth=True, to apply smoothing.\n  grayscale_cam = cam(input_tensor=input_tensor, targets=targets)\n  # In this example grayscale_cam has only one image in the batch:\n  grayscale_cam = grayscale_cam[0, :]\n  visualization = show_cam_on_image(rgb_img, grayscale_cam, use_rgb=True)\n  # You can also get the model outputs without having to redo inference\n  model_outputs = cam.outputs\n\n  import matplotlib.pyplot as plt\n  plt.imshow(visualization)\n  plt.axis('off')\n  plt.show()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":211},"id":"WfHeBAz72jCq","outputId":"1577619d-8cda-43ec-a61e-e3315cf477bc"},"execution_count":15,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'inverse_cams' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-15-144f8563d948>\u001b[0m in \u001b[0;36m<cell line: 43>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0mmetric_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mClassifierOutputSoftmaxTarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m281\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m scores, batch_visualizations = CamMultImageConfidenceChange()(input_tensor, \n\u001b[0;32m---> 44\u001b[0;31m   inverse_cams, targets, model, return_visualization=True)\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0mvisualization\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeprocess_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_visualizations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'inverse_cams' is not defined"]}]},{"cell_type":"code","source":"writer.close()\n# Save the trained model","metadata":{"id":"RBgUx8zpUPEk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.save(model.state_dict(), 'trained_model.pth')\n","metadata":{"id":"qV-By5ywUPKZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%tensorboard --logdir logs/resnet","metadata":{"id":"AKojXSenUFTh"},"execution_count":null,"outputs":[]}]}