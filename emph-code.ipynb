{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9187894,"sourceType":"datasetVersion","datasetId":5554065},{"sourceId":9235599,"sourceType":"datasetVersion","datasetId":5586300}],"dockerImageVersionId":30746,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false},"colab":{"provenance":[],"machine_shape":"hm","gpuType":"T4","name":"Emph code"},"accelerator":"GPU"},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**https://github.com/aladdinpersson/Machine-Learning-Collection/tree/master/ML/Pytorch/Basics/custom_dataset**","metadata":{"id":"1mTzQ8NpUFTf"}},{"cell_type":"code","source":"!pip install tensorflow tensorboard tf-keras-vis grad-cam\nimport os\nimport pandas as pd\nimport torch\nfrom torch.utils.data import Dataset\nfrom skimage import io\nfrom PIL import Image\nimport matplotlib.pyplot as plt\n\nclass Emphysema_Dataset(Dataset):\n    def __init__(self, csv_file, root_dir, transform=None):\n        self.annotations = pd.read_csv(csv_file)\n        self.root_dir = root_dir\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.annotations)\n\n    def __getitem__(self, index):\n        img_path = os.path.join(self.root_dir, self.annotations.iloc[index, 0])\n        image = io.imread(img_path)\n        image = Image.fromarray(image).convert('RGB')  # Convert the NumPy array to a PIL Image\n        y_label = torch.tensor(self.annotations.iloc[index, 1])\n\n        if self.transform:\n            image = self.transform(image)\n\n        return image, y_label\n\n%load_ext tensorboard","metadata":{"id":"ZNOatwc51Psn","colab":{"base_uri":"https://localhost:8080/"},"outputId":"589a264e-0e05-460e-ad38-20629b7b278e","execution":{"iopub.status.busy":"2024-09-03T18:17:29.696146Z","iopub.execute_input":"2024-09-03T18:17:29.696552Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Requirement already satisfied: tensorflow in /opt/conda/lib/python3.10/site-packages (2.15.0)\nRequirement already satisfied: tensorboard in /opt/conda/lib/python3.10/site-packages (2.15.1)\n\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7fb2ddbc12a0>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/tf-keras-vis/\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7fb2ddbc15a0>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/tf-keras-vis/\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7fb2ddbc1750>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/tf-keras-vis/\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"#%tensorboard --logdir logs/resnet\n\n# Import necessary libraries\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision\nimport torchvision.transforms as transforms\nfrom torchvision import models\nfrom pathlib import Path\nfrom PIL import Image\n#import tmm\n\nfrom torch.utils.tensorboard import SummaryWriter\nwriter = SummaryWriter(log_dir='./logs/resnet')\n\n# Set device (use GPU if available)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(device,\"||\",torch.device)\n\n# Load Emphysema_Dataset  (host domain)\ntransform = transforms.Compose([\n  transforms.Resize((224, 224)),  # Resize images to the size expected by ResNet50 originally 1024 x1024\n  transforms.ToTensor(),\n  transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),  # Normalize based on ImageNet stats\n])\n\n\ndataset = Emphysema_Dataset(csv_file = Path(\"/kaggle/input/emphysema-dataset-from-nih-chest-x-ray/Data_Entry_2024.csv\"), root_dir= Path(\"/kaggle/input/emphysema-dataset-from-nih-chest-x-ray/emphReform/emphReform\"), transform=transform)\n\ntrain_size = int(0.3 * len(dataset)) ## 0.6 is 60% split for train and testclea\ntest_size = len(dataset) - train_size\ntrain_set, test_set = torch.utils.data.random_split(dataset, [train_size, test_size])\n\ntrain_loader = torch.utils.data.DataLoader(train_set, batch_size=32, shuffle=True)\ntest_loader = torch.utils.data.DataLoader(test_set, batch_size=32, shuffle=False)","metadata":{"id":"4Hthdgbr1Pso","outputId":"fd05de1f-86f1-4daa-f2e1-56b7a34a8347","colab":{"base_uri":"https://localhost:8080/"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def modelResnet():\n\n    model = models.resnet50(pretrained=True)\n\n\n    #model = timm.create_model('xception', pretrained=True)\n    #model.eval()\n\n    model.fc = nn.Linear(model.fc.in_features, 2)  # Emphysema_Dataset has 2 classes\n    model = model.to(device)\n\n    # Define loss function and optimizer\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.Adam(model.parameters(), lr=0.001)\n\n\n    return model, criterion, optimizer","metadata":{"id":"c1HpDg61Y0-J"},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"from torchvision.models import vit_b_16\n\ndef modelViT():\n\n    model = vit_b_16(pretrained=True)\n\n    #model.fc = nn.Linear(model.fc.in_features, 2)  # Emphysema_Dataset has 2 classes\n    model.heads.head = nn.Linear(model.heads.head.in_features, 2)\n    model = model.to(device)\n\n    # Define loss function and optimizer\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.Adam(model.parameters(), lr=0.001)\n\n    print(model)\n\n\n    return model, criterion, optimizer","metadata":{"id":"s_Zz4qaVY4Tq"},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"\n# Training function\ndef train_model(model, train_loader, criterion, optimizer, num_epochs):\n    model.train()\n    print(\"i am here with\", num_epochs)\n    for epoch in range(num_epochs):\n        print(f'Epoch {epoch + 1}/{num_epochs}')\n        print('-' * 10)\n        running_loss = 0.0\n        for inputs, labels in train_loader:\n            inputs, labels = inputs.to(device), labels.to(device)\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            running_loss += loss.item()\n\n            # Log the training loss\n        epoch_loss = running_loss / len(train_loader)\n        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {running_loss / len(train_loader):.4f}')\n\n        writer.add_scalar('Training Loss', epoch_loss, epoch + 1)\n\n\n    model.eval()\n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for inputs, labels in test_loader:\n            inputs, labels = inputs.to(device), labels.to(device)\n            outputs = model(inputs)\n            _, predicted = torch.max(outputs.data, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n\n    accuracy = 100 * correct / total\n    print(f'Accuracy of the model on the test images: {accuracy:.2f}%')\n\n\n    # Log the test accuracy\n    writer.add_scalar('Test Accuracy', accuracy, epoch + 1)","metadata":{"id":"L4LxYPb8bWE-"},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# Train and evaluate the model\n#model = Image.fromarray(model)\n\nWhichModel = input(\"what model, resnet or vit? \")\nif WhichModel == \"resnet\":\n    model, criterion, optimizer = modelResnet()\nelif WhichModel == \"vit\":\n    model, criterion, optimizer = modelViT()\nelse:\n    raise Exception(\"Sorry, Chose from list\")\n\nepochs = input(\"How Many Epochs?: \")\n\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QzlPcKe5UFTh","outputId":"0ecbdf85-e0dd-4465-e154-8ea8db7319ac"},"execution_count":8,"outputs":[{"name":"stdout","output_type":"stream","text":"what model, resnet or vit? resnet\n"},{"output_type":"stream","name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n\n  warnings.warn(\n\n/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n\n  warnings.warn(msg)\n\nDownloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n\n100%|██████████| 97.8M/97.8M [00:00<00:00, 152MB/s]\n"},{"name":"stdout","output_type":"stream","text":"How Many Epochs?: 1\n"}]},{"cell_type":"code","source":"train_model(model, train_loader, criterion, optimizer, num_epochs=int(epochs))","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9v3FXGpdbBHL","outputId":"89ca330d-7ba0-4e96-85e7-bd4fdc30592e"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":"i am here with 1\n\nEpoch 1/1\n\n----------\n\nEpoch [1/1], Loss: 0.7109\n\nAccuracy of the model on the test images: 57.68%\n"}]},{"cell_type":"markdown","source":"","metadata":{"id":"N7GAg2y59InN"}},{"cell_type":"markdown","source":"https://github.com/jacobgil/pytorch-grad-cam","metadata":{"id":"CBgsGp3bbOW8"}},{"cell_type":"code","source":"from pytorch_grad_cam import GradCAM, HiResCAM, ScoreCAM, GradCAMPlusPlus, AblationCAM, XGradCAM, EigenCAM, FullGrad\nfrom pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\nfrom pytorch_grad_cam.utils.image import show_cam_on_image, deprocess_image, preprocess_image\nimport cv2\nimport numpy as np\n\n\nrgb_img = cv2.imread(\"/kaggle/input/emphysema-dataset-from-nih-chest-x-ray/emphReform/emphReform/00000002_000.png\", 1)[:, :, ::-1]\nrgb_img = np.float32(rgb_img) / 255\ninput_tensor = preprocess_image(rgb_img, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]).to(device)\n\ntarget_layers = [model.layer4[-1]]\n# Note: input_tensor can be a batch tensor with several images!\n\n# We have to specify the target we want to generate the CAM for.\ntargets = [ClassifierOutputTarget(1)]\n\n# Construct the CAM object once, and then re-use it on many images.\nwith GradCAM(model=model, target_layers=target_layers) as cam:\n  # You can also pass aug_smooth=True and eigen_smooth=True, to apply smoothing.\n  grayscale_cam = cam(input_tensor=input_tensor, targets=targets)\n  # In this example grayscale_cam has only one image in the batch:\n  grayscale_cam = grayscale_cam[0, :]\n  visualization = show_cam_on_image(rgb_img, grayscale_cam, use_rgb=True)\n  # You can also get the model outputs without having to redo inference\n  model_outputs = cam.outputs\n\n  import matplotlib.pyplot as plt\n  plt.imshow(visualization)\n  plt.axis('off')\n  plt.show()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":211},"id":"WfHeBAz72jCq","outputId":"1577619d-8cda-43ec-a61e-e3315cf477bc"},"execution_count":15,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'inverse_cams' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-15-144f8563d948>\u001b[0m in \u001b[0;36m<cell line: 43>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0mmetric_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mClassifierOutputSoftmaxTarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m281\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m scores, batch_visualizations = CamMultImageConfidenceChange()(input_tensor, \n\u001b[0;32m---> 44\u001b[0;31m   inverse_cams, targets, model, return_visualization=True)\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0mvisualization\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeprocess_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_visualizations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'inverse_cams' is not defined"]}]},{"cell_type":"code","source":"writer.close()\n# Save the trained model","metadata":{"id":"RBgUx8zpUPEk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.save(model.state_dict(), 'trained_model.pth')\n","metadata":{"id":"qV-By5ywUPKZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%tensorboard --logdir logs/resnet","metadata":{"id":"AKojXSenUFTh"},"execution_count":null,"outputs":[]}]}