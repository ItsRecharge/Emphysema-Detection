{"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1618416,"sourceType":"datasetVersion","datasetId":955838}],"dockerImageVersionId":30746,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false},"colab":{"gpuType":"A100","provenance":[]},"accelerator":"GPU"},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**https://github.com/aladdinpersson/Machine-Learning-Collection/tree/master/ML/Pytorch/Basics/custom_dataset**","metadata":{"id":"1mTzQ8NpUFTf"}},{"cell_type":"code","source":"!pip install tensorflow tensorboard tf-keras-vis grad-cam\nimport os\nimport pandas as pd\nimport torch\nfrom torch.utils.data import Dataset\nfrom skimage import io\nfrom PIL import Image\nimport matplotlib.pyplot as plt\n\nclass CheXpertDataset(Dataset):\n    def __init__(self, csv_file, root_dir, transform=None):\n        self.annotations = pd.read_csv(csv_file)\n        self.root_dir = root_dir\n        self.transform = transform\n        self.annotations = self.annotations.fillna(0) ######### USE HERE BECAUSE CHEXPERT IS MULT-Class\n\n    def __len__(self):\n        return len(self.annotations)\n\n    def __getitem__(self, index):\n        img_path = os.path.join(self.root_dir, self.annotations.iloc[index, 0])\n        image = io.imread(img_path)\n        image = Image.fromarray(image).convert('RGB')  # Convert the NumPy array to a PIL Image\n        y_label = torch.tensor(self.annotations.iloc[index, 5:19].values.astype(float)) #######  add colums for chexpert, 14 lables ## 5:19].values.astype(float))\n\n        if self.transform:\n            image = self.transform(image)\n\n        return image, y_label\n\n%load_ext tensorboard","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZNOatwc51Psn","outputId":"e53f14d4-3917-4eb5-8a65-5beb1600c897"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.0)\n","Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (2.17.0)\n","Collecting tf-keras-vis\n","  Downloading tf_keras_vis-0.8.7-py3-none-any.whl.metadata (10 kB)\n","Collecting grad-cam\n","  Downloading grad-cam-1.5.4.tar.gz (7.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m57.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.11.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n","Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.1)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.1)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (71.0.4)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.5.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n","Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.1)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n","Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.26.4)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.7)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.0.4)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from tf-keras-vis) (1.13.1)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from tf-keras-vis) (10.4.0)\n","Requirement already satisfied: deprecated in /usr/local/lib/python3.10/dist-packages (from tf-keras-vis) (1.2.14)\n","Requirement already satisfied: imageio in /usr/local/lib/python3.10/dist-packages (from tf-keras-vis) (2.35.1)\n","Requirement already satisfied: torch>=1.7.1 in /usr/local/lib/python3.10/dist-packages (from grad-cam) (2.4.1+cu121)\n","Requirement already satisfied: torchvision>=0.8.2 in /usr/local/lib/python3.10/dist-packages (from grad-cam) (0.19.1+cu121)\n","Collecting ttach (from grad-cam)\n","  Downloading ttach-0.0.3-py3-none-any.whl.metadata (5.2 kB)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from grad-cam) (4.66.5)\n","Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from grad-cam) (4.10.0.84)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from grad-cam) (3.7.1)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from grad-cam) (1.5.2)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n","Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (13.9.2)\n","Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n","Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.13.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->grad-cam) (3.16.1)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->grad-cam) (1.13.3)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->grad-cam) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->grad-cam) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->grad-cam) (2024.6.1)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard) (2.1.5)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->grad-cam) (1.3.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->grad-cam) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->grad-cam) (4.54.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->grad-cam) (1.4.7)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->grad-cam) (3.1.4)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->grad-cam) (2.8.2)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->grad-cam) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->grad-cam) (3.5.0)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.18.0)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.7.1->grad-cam) (1.3.0)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n","Downloading tf_keras_vis-0.8.7-py3-none-any.whl (52 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.5/52.5 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading ttach-0.0.3-py3-none-any.whl (9.8 kB)\n","Building wheels for collected packages: grad-cam\n","  Building wheel for grad-cam (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for grad-cam: filename=grad_cam-1.5.4-py3-none-any.whl size=39587 sha256=75537115dc94c1afd0eb4fd8f71c297c6f8372d884c8762f0bfa1d059aff0ac4\n","  Stored in directory: /root/.cache/pip/wheels/50/b0/82/1f97b5348c7fe9f0ce0ba18497202cafa5dec4562bd5292680\n","Successfully built grad-cam\n","Installing collected packages: ttach, tf-keras-vis, grad-cam\n","Successfully installed grad-cam-1.5.4 tf-keras-vis-0.8.7 ttach-0.0.3\n"]}],"execution_count":null},{"cell_type":"code","source":"from google.colab import output\n\n# JavaScript code to prevent timeout\ncode = \"\"\"\nfunction KeepClicking(){\n    console.log(\"Clicking to prevent timeout\");\n    document.querySelector(\"colab-toolbar-button\").click();\n}\nsetInterval(KeepClicking, 60000);\n\"\"\"\n\noutput.eval_js(code)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"id":"_wxFt-AVkiGo","outputId":"1ca39593-96fb-47d8-d1e3-4ab90d95d958"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["32"]},"metadata":{},"execution_count":3}],"execution_count":null},{"cell_type":"code","source":"#%tensorboard --logdir logs/resnet\n\n# Import necessary libraries\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision\nimport torchvision.transforms as transforms\nfrom torchvision import models\nfrom pathlib import Path\nfrom PIL import Image\n#import tmm\n\nfrom torch.utils.tensorboard import SummaryWriter\nwriter = SummaryWriter(log_dir='./logs/resnet')\n\n# Set device (use GPU if available)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(device,\"||\",torch.device)\n\n# Load Emphysema_Dataset  (host domain)\ntransform = transforms.Compose([\n  transforms.Resize((224, 224)),  # Resize images to the size expected by ResNet50 originally 1024 x1024\n  transforms.ToTensor(),\n  transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),  # Normalize based on ImageNet stats\n])\n\n\ntrainData = \"/kaggle/input/chexpert/CheXpert-v1.0-small/train.csv\"\ntestData = \"/kaggle/input/chexpert/CheXpert-v1.0-small/valid.csv\"\ntrainImgDir = \"/kaggle/input/chexpert\"\ntestImgDir = \"/kaggle/input/chexpert\"\n\ntrain_dataset = CheXpertDataset(csv_file=trainData, root_dir=trainImgDir, transform=transform)\ntest_dataset = CheXpertDataset(csv_file=testData, root_dir=testImgDir, transform=transform)\n\ntrain_loader = torch.utils.data.DataLoader(train_dataset, batch_size=900, shuffle=True)\ntest_loader = torch.utils.data.DataLoader(test_dataset, batch_size=900, shuffle=False)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4Hthdgbr1Pso","outputId":"968d0151-121e-4e37-cf74-18d187aaab0c"},"outputs":[{"output_type":"stream","name":"stdout","text":["cuda || <class 'torch.device'>\n"]}],"execution_count":null},{"cell_type":"code","source":"def modelResnet():\n\n    model = models.resnet18(pretrained=False)\n\n\n    #model = timm.create_model('xception', pretrained=True)\n    #model.eval()\n\n    model.fc = nn.Linear(model.fc.in_features, 14)  # CheXpert has 14 classes\n    model.load_state_dict(torch.load('/content/drive/My Drive/trained_model.pth'))  # Load the saved state\n\n    model = model.to(device)\n\n    # Define loss function and optimizer\n    criterion = nn.BCEWithLogitsLoss() ######## https://discuss.pytorch.org/t/loss-function-crossentropyloss-vs-bcewithlogitsloss/16089\n    optimizer = optim.Adam(model.parameters(), lr=0.001)\n\n\n    return model, criterion, optimizer","metadata":{"id":"c1HpDg61Y0-J"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from google.colab import drive\nimport torch\n\n# Mount Google Drive\ndrive.mount('/content/drive')\n\ndef train_model(model, train_loader, criterion, optimizer, num_epochs):\n    model.train()\n    print(\"Training for\", num_epochs, \"epochs\")\n\n    for epoch in range(num_epochs):\n        print(f'Epoch {epoch + 1}/{num_epochs}')\n        print('-' * 10)\n        running_loss = 0.0\n\n        for inputs, labels in train_loader:\n            inputs, labels = inputs.to(device), labels.to(device)\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            running_loss += loss.item()\n\n        # Log training loss to TensorBoard\n        epoch_loss = running_loss / len(train_loader)\n        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {epoch_loss:.4f}')\n        writer.add_scalar('Training Loss', epoch_loss, epoch + 1)\n\n        # Save the model state every 10 epochs and overwrite old model\n        if (epoch + 1) % 2 == 0:\n            model_path = '/content/drive/My Drive/trained_model.pth'\n            torch.save(model.state_dict(), model_path)\n            print(f\"Model saved to Google Drive after epoch {epoch + 1}\")\n\n    # At the end of training, save the model\n    final_model_path = '/content/drive/My Drive/trained_model_final.pth'\n    torch.save(model.state_dict(), final_model_path)\n    print(\"Final model saved to Google Drive.\")\n\n    writer.close()\n\n# Example usage:\n# model, criterion, optimizer = modelResnet()\n# train_model(model, train_loader, criterion, optimizer, num_epochs=50)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"L4LxYPb8bWE-","outputId":"0c46afbc-663a-49bb-e8ed-29d9fe0f1f2d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"execution_count":null},{"cell_type":"code","source":"# Train and evaluate the model\n#model = Image.fromarray(model)\nmodel, criterion, optimizer = modelResnet()\n\nepochs = 0\n\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QzlPcKe5UFTh","outputId":"c36b7cbe-a508-4295-cf1e-a9dfbea7bb4a"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n","  warnings.warn(msg)\n","<ipython-input-5-8db6afb046b8>:10: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  model.load_state_dict(torch.load('/content/drive/My Drive/trained_model.pth'))  # Load the saved state\n"]}],"execution_count":null},{"cell_type":"code","source":"train_model(model, train_loader, criterion, optimizer, num_epochs=int(epochs))","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9v3FXGpdbBHL","outputId":"fe99052b-cc04-4efc-9364-279fd4fb2074"},"outputs":[{"output_type":"stream","name":"stdout","text":["Training for 0 epochs\n","Final model saved to Google Drive.\n"]}],"execution_count":null},{"cell_type":"code","source":"f1, accuracy = test_model(model, test_loader, criterion)\nprint(f\"F1 Score: {f1:.4f}\")\nprint(f\"Accuracy: {accuracy:.4f}\")","metadata":{"id":"YkWbGjjsiFY5","colab":{"base_uri":"https://localhost:8080/"},"outputId":"cf7ba9b8-8e3f-4e69-d79f-ce8cd15396fa"},"outputs":[{"output_type":"stream","name":"stdout","text":["F1 Score: 0.0590\n","Accuracy of the model on the test images: 11.11%\n","F1 Score: 0.0590\n","Accuracy: 11.1111\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"]}],"execution_count":null},{"cell_type":"code","source":"writer.close()\n# Save the trained model","metadata":{"id":"RBgUx8zpUPEk"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"torch.save(model.state_dict(), '/content/drive/trained_model.pth')\ntorch.save(model.state_dict(), 'trained_model.pth')\n","metadata":{"id":"qV-By5ywUPKZ"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%tensorboard --logdir logs/resnet","metadata":{"id":"AKojXSenUFTh"},"outputs":[],"execution_count":null}]}